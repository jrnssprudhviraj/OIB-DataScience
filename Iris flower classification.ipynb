{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f24987-bcc3-42bc-afd9-01eb96aa276d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows of the Iris dataset:\n",
      "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
      "0      1            5.1           3.5            1.4           0.2   \n",
      "1      2            4.9           3.0            1.4           0.2   \n",
      "2      3            4.7           3.2            1.3           0.2   \n",
      "3      4            4.6           3.1            1.5           0.2   \n",
      "4      5            5.0           3.6            1.4           0.2   \n",
      "..   ...            ...           ...            ...           ...   \n",
      "145  146            6.7           3.0            5.2           2.3   \n",
      "146  147            6.3           2.5            5.0           1.9   \n",
      "147  148            6.5           3.0            5.2           2.0   \n",
      "148  149            6.2           3.4            5.4           2.3   \n",
      "149  150            5.9           3.0            5.1           1.8   \n",
      "\n",
      "            Species  \n",
      "0       Iris-setosa  \n",
      "1       Iris-setosa  \n",
      "2       Iris-setosa  \n",
      "3       Iris-setosa  \n",
      "4       Iris-setosa  \n",
      "..              ...  \n",
      "145  Iris-virginica  \n",
      "146  Iris-virginica  \n",
      "147  Iris-virginica  \n",
      "148  Iris-virginica  \n",
      "149  Iris-virginica  \n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset into a DataFrame\n",
    "iris_df = pd.read_csv('Iris.csv')\n",
    "\n",
    "# Display all rows of the dataset\n",
    "print(\"All rows of the Iris dataset:\")\n",
    "print(iris_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa4fa48-0a3d-411a-a0c1-d43150b796f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "\n",
      "Column names:\n",
      "Index(['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
      "       'Species'],\n",
      "      dtype='object')\n",
      "\n",
      "Shape of the dataset:\n",
      "(150, 6)\n",
      "\n",
      "Missing values in each column:\n",
      "Id               0\n",
      "SepalLengthCm    0\n",
      "SepalWidthCm     0\n",
      "PetalLengthCm    0\n",
      "PetalWidthCm     0\n",
      "Species          0\n",
      "dtype: int64\n",
      "\n",
      "Data types and memory usage:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             150 non-null    int64  \n",
      " 1   SepalLengthCm  150 non-null    float64\n",
      " 2   SepalWidthCm   150 non-null    float64\n",
      " 3   PetalLengthCm  150 non-null    float64\n",
      " 4   PetalWidthCm   150 non-null    float64\n",
      " 5   Species        150 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n",
      "None\n",
      "\n",
      "Basic statistics for numerical columns:\n",
      "               Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "count  150.000000     150.000000    150.000000     150.000000    150.000000\n",
      "mean    75.500000       5.843333      3.054000       3.758667      1.198667\n",
      "std     43.445368       0.828066      0.433594       1.764420      0.763161\n",
      "min      1.000000       4.300000      2.000000       1.000000      0.100000\n",
      "25%     38.250000       5.100000      2.800000       1.600000      0.300000\n",
      "50%     75.500000       5.800000      3.000000       4.350000      1.300000\n",
      "75%    112.750000       6.400000      3.300000       5.100000      1.800000\n",
      "max    150.000000       7.900000      4.400000       6.900000      2.500000\n"
     ]
    }
   ],
   "source": [
    "# 1. Understanding the Structure and Contents\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(iris_df.head())\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(iris_df.columns)\n",
    "\n",
    "print(\"\\nShape of the dataset:\")\n",
    "print(iris_df.shape)\n",
    "\n",
    "# 2. Checking for Missing Values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(iris_df.isnull().sum())\n",
    "\n",
    "# 3. Checking Data Types\n",
    "print(\"\\nData types and memory usage:\")\n",
    "print(iris_df.info())\n",
    "\n",
    "# 4. Basic Statistics\n",
    "print(\"\\nBasic statistics for numerical columns:\")\n",
    "print(iris_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59143ef4-7c56-4d80-ad87-996f785452b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Id               0\n",
      "SepalLengthCm    0\n",
      "SepalWidthCm     0\n",
      "PetalLengthCm    0\n",
      "PetalWidthCm     0\n",
      "Species          0\n",
      "dtype: int64\n",
      "\n",
      "Preprocessed dataset:\n",
      "         Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
      "0 -1.720542      -0.900681      1.032057      -1.341272     -1.312977   \n",
      "1 -1.697448      -1.143017     -0.124958      -1.341272     -1.312977   \n",
      "2 -1.674353      -1.385353      0.337848      -1.398138     -1.312977   \n",
      "3 -1.651258      -1.506521      0.106445      -1.284407     -1.312977   \n",
      "4 -1.628164      -1.021849      1.263460      -1.341272     -1.312977   \n",
      "\n",
      "   Species_Iris-setosa  Species_Iris-versicolor  Species_Iris-virginica  \n",
      "0                    1                        0                       0  \n",
      "1                    1                        0                       0  \n",
      "2                    1                        0                       0  \n",
      "3                    1                        0                       0  \n",
      "4                    1                        0                       0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = iris_df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Handle missing values (if any)\n",
    "if missing_values.sum() > 0:\n",
    "    # Strategy: Impute missing values with mean for numerical columns\n",
    "    numerical_features = iris_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    numerical_imputer = SimpleImputer(strategy='mean')\n",
    "    numerical_imputer.fit(iris_df[numerical_features])\n",
    "    \n",
    "    iris_df[numerical_features] = numerical_imputer.transform(iris_df[numerical_features])\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "iris_df_encoded = pd.get_dummies(iris_df)\n",
    "\n",
    "# Standardize numerical features (if necessary)\n",
    "numerical_features = iris_df_encoded.select_dtypes(include=['float64', 'int64']).columns\n",
    "numerical_scaler = StandardScaler()\n",
    "iris_df_encoded[numerical_features] = numerical_scaler.fit_transform(iris_df_encoded[numerical_features])\n",
    "\n",
    "# Display preprocessed dataset\n",
    "print(\"\\nPreprocessed dataset:\")\n",
    "print(iris_df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4a739c3-6f92-43e6-ae7d-1f5c588c29f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Id               0\n",
      "SepalLengthCm    0\n",
      "SepalWidthCm     0\n",
      "PetalLengthCm    0\n",
      "PetalWidthCm     0\n",
      "Species          0\n",
      "dtype: int64\n",
      "Shape of X_train: (120, 5)\n",
      "Shape of X_test: (30, 5)\n",
      "Shape of y_train: (120,)\n",
      "Shape of y_test: (30,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = iris_df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Handle missing values (if any)\n",
    "if missing_values.sum() > 0:\n",
    "    # Strategy: Impute missing values with mean for numerical columns\n",
    "    numerical_features = iris_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    numerical_imputer = SimpleImputer(strategy='mean')\n",
    "    numerical_imputer.fit(iris_df[numerical_features])\n",
    "    \n",
    "    iris_df[numerical_features] = numerical_imputer.transform(iris_df[numerical_features])\n",
    "\n",
    "# Get the target variable\n",
    "y = iris_df['Species']\n",
    "\n",
    "# Drop the target variable from the original DataFrame to get the features\n",
    "X = iris_df.drop(columns=['Species'])\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a0d7954-be10-4f97-b50f-866244637bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             150 non-null    int64  \n",
      " 1   SepalLengthCm  150 non-null    float64\n",
      " 2   SepalWidthCm   150 non-null    float64\n",
      " 3   PetalLengthCm  150 non-null    float64\n",
      " 4   PetalWidthCm   150 non-null    float64\n",
      " 5   Species        150 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "               Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "count  150.000000     150.000000    150.000000     150.000000    150.000000\n",
      "mean    75.500000       5.843333      3.054000       3.758667      1.198667\n",
      "std     43.445368       0.828066      0.433594       1.764420      0.763161\n",
      "min      1.000000       4.300000      2.000000       1.000000      0.100000\n",
      "25%     38.250000       5.100000      2.800000       1.600000      0.300000\n",
      "50%     75.500000       5.800000      3.000000       4.350000      1.300000\n",
      "75%    112.750000       6.400000      3.300000       5.100000      1.800000\n",
      "max    150.000000       7.900000      4.400000       6.900000      2.500000\n",
      "\n",
      "Missing values in each column:\n",
      "Id               0\n",
      "SepalLengthCm    0\n",
      "SepalWidthCm     0\n",
      "PetalLengthCm    0\n",
      "PetalWidthCm     0\n",
      "Species          0\n",
      "dtype: int64\n",
      "\n",
      "KNN Accuracy: 1.0\n",
      "\n",
      "KNN Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       1.00      1.00      1.00         9\n",
      " Iris-virginica       1.00      1.00      1.00        11\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "KNN Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Decision Tree Accuracy: 1.0\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       1.00      1.00      1.00         9\n",
      " Iris-virginica       1.00      1.00      1.00        11\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Decision Tree Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "iris_df = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "# Explore the dataset\n",
    "print(\"Dataset Overview:\")\n",
    "print(iris_df.head())\n",
    "print(\"\\nDataset Information:\")\n",
    "print(iris_df.info())\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(iris_df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(iris_df.isnull().sum())\n",
    "\n",
    "# Preprocess the data\n",
    "X = iris_df.drop(columns=['Species'])  # Features\n",
    "y = iris_df['Species']  # Target variable\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the KNN model\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with KNN\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate KNN model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"\\nKNN Accuracy:\", accuracy_knn)\n",
    "\n",
    "print(\"\\nKNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "print(\"\\nKNN Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "# Train the Decision Tree model\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with Decision Tree\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate Decision Tree model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"\\nDecision Tree Accuracy:\", accuracy_dt)\n",
    "\n",
    "print(\"\\nDecision Tree Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "print(\"\\nDecision Tree Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80a3afed-d183-419a-9c8f-8ebff3c1e27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics for SVM Model:\n",
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report for SVM Model:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       1.00      1.00      1.00         9\n",
      " Iris-virginica       1.00      1.00      1.00        11\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Evaluation Metrics for KNN Model:\n",
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report for KNN Model:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       1.00      1.00      1.00         9\n",
      " Iris-virginica       1.00      1.00      1.00        11\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Evaluation Metrics for Decision Tree Model:\n",
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report for Decision Tree Model:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       1.00      1.00      1.00         9\n",
      " Iris-virginica       1.00      1.00      1.00        11\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the SVM model\n",
    "print(\"\\nEvaluation Metrics for SVM Model:\")\n",
    "accuracy_svm = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "\n",
    "print(\"\\nClassification Report for SVM Model:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluate the KNN model\n",
    "print(\"\\nEvaluation Metrics for KNN Model:\")\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"Accuracy:\", accuracy_knn)\n",
    "\n",
    "print(\"\\nClassification Report for KNN Model:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Evaluate the Decision Tree model\n",
    "print(\"\\nEvaluation Metrics for Decision Tree Model:\")\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "\n",
    "print(\"\\nClassification Report for Decision Tree Model:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51bee12f-b78a-4c05-9c97-10358b3ad8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics for SVM Model:\n",
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report for SVM Model:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       1.00      1.00      1.00         9\n",
      " Iris-virginica       1.00      1.00      1.00        11\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Confusion Matrix for SVM Model:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Train the SVM model\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "print(\"\\nEvaluation Metrics for SVM Model:\")\n",
    "accuracy_svm = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "\n",
    "print(\"\\nClassification Report for SVM Model:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Obtain the confusion matrix for SVM Model\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix for SVM Model:\")\n",
    "print(conf_matrix_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ccf1442-c09a-466a-bde2-975a1fd4cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample New Data:\n",
      "[[8.87356029 5.94635796 6.05468319 8.16400432]\n",
      " [1.49478335 0.45646617 8.57540739 4.4047873 ]\n",
      " [3.27646298 2.12464147 4.31310585 3.54617175]\n",
      " [2.62689379 8.97743014 5.34101102 8.23145929]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate random data for testing\n",
    "num_samples = 4\n",
    "num_features = 4  # Assuming 4 features: SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm\n",
    "\n",
    "# Generate random values for each feature\n",
    "X_new = np.random.rand(num_samples, num_features) * 10  # Scale the random values to a range of 0 to 10\n",
    "\n",
    "print(\"Sample New Data:\")\n",
    "print(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34fc7562-9117-4fce-9c42-acefe177dbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model (SVM) Accuracy: 1.0\n",
      "Initial Model (SVM) Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Alternative Algorithm (Random Forest) Accuracy: 1.0\n",
      "Alternative Algorithm (Random Forest) Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train an initial model (e.g., SVM)\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the initial model (e.g., SVM)\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Initial Model (SVM) Accuracy:\", accuracy_svm)\n",
    "print(\"Initial Model (SVM) Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Step 6: Experiment with a different algorithm (e.g., Random Forest)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Evaluate the alternative algorithm (e.g., Random Forest)\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Alternative Algorithm (Random Forest) Accuracy:\", accuracy_rf)\n",
    "print(\"Alternative Algorithm (Random Forest) Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Step 14: Finalize the model and deploy it\n",
    "# (Finalization and deployment code not included in this example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc0c8f4b-0762-4de0-adcd-5851c106003b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation Score: 0.95\n",
      "Standard Deviation of Cross-Validation Scores: 0.06123724356957944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Step 1: Initialize the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Step 2: Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(svm_classifier, X_train_scaled, y_train, cv=5)\n",
    "\n",
    "# Step 3: Calculate the mean and standard deviation of the cross-validation scores\n",
    "mean_cv_score = cv_scores.mean()\n",
    "std_cv_score = cv_scores.std()\n",
    "\n",
    "# Step 4: Print the mean and standard deviation of the cross-validation scores\n",
    "print(\"Mean Cross-Validation Score:\", mean_cv_score)\n",
    "print(\"Standard Deviation of Cross-Validation Scores:\", std_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f71307a-1e1f-4657-b878-76277844915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Step 1: Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Step 2: Train the Random Forest classifier on the training data\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 3: Make predictions on the test data\n",
    "y_pred_rf = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Step 4: Evaluate the Random Forest classifier\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy of Random Forest Classifier:\", accuracy_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e31254b-cec9-45f8-a838-0caaf08b4ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
